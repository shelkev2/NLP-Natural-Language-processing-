{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TOPIC modelling NLP basic .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlPTorM8uxKV",
        "colab_type": "text"
      },
      "source": [
        "# WHAT IS TOPIC MODELING?  \n",
        "Topic models provide an efficient way to analyze large volumes of text. While there are many different types of topic modeling, the most common and arguably the most useful for search engines is Latent Dirichlet Allocation, or LDA. Topic models based on LDA are a form of text data mining and statistical machine learning which consist of:\n",
        "\n",
        "Clustering words into “topics”.  \n",
        "Clustering documents into “mixtures of topics”.    \n",
        "More specifically: A Bayesian inference model that associates each document with a probability distribution over topics, where topics are probability distributions over words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzKjX6YIvAFg",
        "colab_type": "text"
      },
      "source": [
        "# What is a Probability Distribution?\n",
        "\n",
        "A probability distribution is an equation which links each possible outcome of a random variable with its probability of occurrence. For example, if we flip a coin twice, we have four possible outcomes: Heads and Heads, Heads and Tails, Tails and Heads, Tails and Tails. Now, if we make heads = 1 and tails = 0, we could have a random variable, X, with three possible outcomes represented by x: 0, 1 and 2. So the P(X=x), or the probability distribution of X, is:  \n",
        "x=0 -> 0.25  \n",
        "x=1 -> 0.50  \n",
        "x=2 -> 0.25  \n",
        "\n",
        "In topic modeling, a document's probability distribution over topics, i.e. the mixture of topics most likely being discussed in that document, might look like this:  \n",
        "\n",
        "document 1  \n",
        "\n",
        "θ’1topic 1 = .33  \n",
        "θ’1topic 2 = .33  \n",
        "θ’1topic 3 = .33  \n",
        "\n",
        "A topic's probability distribution over words, i.e. the words most likely to be used in a given topic, might look like this for the top 3 words in the topic:  \n",
        "\n",
        "topic 1  \n",
        "\n",
        "φ'1bank = .39  \n",
        "φ'1money = .32  \n",
        "φ'1loan = .29  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JLGaQmNvLt3",
        "colab_type": "text"
      },
      "source": [
        "Topics can be defined as “a repeating pattern of co-occurring terms in a corpus”. A good topic model should result in – “health”, “doctor”, “patient”, “hospital” for a topic – Healthcare, and “farm”, “crops”, “wheat” for a topic – “Farming”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIuDR44Fvcf7",
        "colab_type": "text"
      },
      "source": [
        "LDA assumes documents are produced from a mixture of topics. Those topics then generate words based on their probability distribution. Given a dataset of documents, LDA backtracks and tries to figure out what topics would create those documents in the first place.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYTP20jmvzn_",
        "colab_type": "text"
      },
      "source": [
        "# Parameters of LDA\n",
        "\n",
        "Alpha and Beta Hyperparameters – \n",
        "\n",
        "alpha represents document-topic density and\n",
        "\n",
        "Beta represents topic-word density.\n",
        "\n",
        "\n",
        "Higher the value of alpha, documents are composed of more topics and lower the value of alpha, documents contain fewer topics. \n",
        "\n",
        "On the other hand, higher the beta, topics are composed of a large number of words in the corpus, and with the lower value of beta, they are composed of few words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4EKnGiivMfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc1 = \"Sugar is bad to consume. My sister likes to have sugar, but not my father.\"\n",
        "doc2 = \"My father spends a lot of time driving my sister around to dance practice.\"\n",
        "doc3 = \"Doctors suggest that driving may cause increased stress and blood pressure.\"\n",
        "doc4 = \"Sometimes I feel pressure to perform well at school, but my father never seems to drive my sister to do better.\"\n",
        "doc5 = \"Health experts say that Sugar is not good for your lifestyle.\"\n",
        "\n",
        "# compile documents\n",
        "doc_complete = [doc1, doc2, doc3, doc4, doc5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljb1MGN8wzmJ",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoK1w6uOwImy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "890980cc-cecd-4210-ce8a-2a30c42a8d12"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "import string\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "exclude = set(string.punctuation) \n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def clean(doc):\n",
        "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
        "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
        "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
        "    return normalized\n",
        "  \n",
        "\n",
        "doc_clean = [clean(doc).split() for doc in doc_complete] "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3lFSBN7xRfV",
        "colab_type": "text"
      },
      "source": [
        "# Preparing Document-Term Matrix\n",
        "To run any mathematical model on text corpus, it is a good practice to convert it into a matrix representation. LDA model looks for repeating term patterns in the entire DT matrix. Python provides many great libraries for text mining practices, “gensim” is one such clean and beautiful library to handle text data. It is scalable, robust and efficient. Following code shows how to convert a corpus into a document-term matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hDnM3gsw_R7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "437de4fd-fa4f-4bd8-b886-037e6c5b4873"
      },
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "# Creating the term dictionary of our courpus, where every unique term is assigned an index.\n",
        "dictionary = corpora.Dictionary(doc_clean)\n",
        "\n",
        "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
        "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
        "\n",
        "doc_term_matrix"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)],\n",
              " [(2, 1), (4, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)],\n",
              " [(8, 1),\n",
              "  (13, 1),\n",
              "  (14, 1),\n",
              "  (15, 1),\n",
              "  (16, 1),\n",
              "  (17, 1),\n",
              "  (18, 1),\n",
              "  (19, 1),\n",
              "  (20, 1)],\n",
              " [(2, 1),\n",
              "  (4, 1),\n",
              "  (18, 1),\n",
              "  (21, 1),\n",
              "  (22, 1),\n",
              "  (23, 1),\n",
              "  (24, 1),\n",
              "  (25, 1),\n",
              "  (26, 1),\n",
              "  (27, 1),\n",
              "  (28, 1),\n",
              "  (29, 1)],\n",
              " [(5, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb6ahMWax7DQ",
        "colab_type": "text"
      },
      "source": [
        "# Running LDA Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mO_2rUExm-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Lda = gensim.models.ldamodel.LdaModel\n",
        "\n",
        "# Running and Trainign LDA model on the document term matrix.\n",
        "ldamodel = Lda(doc_term_matrix, num_topics=3, id2word = dictionary, passes=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWTNxLK0ypNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5e8790e2-30db-47ef-a0bc-2581bfd89726"
      },
      "source": [
        "print(ldamodel.print_topics(num_topics=3, num_words=4))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.075*\"expert\" + 0.075*\"lifestyle\" + 0.075*\"health\" + 0.075*\"say\"'), (1, '0.072*\"father\" + 0.072*\"sister\" + 0.041*\"perform\" + 0.041*\"seems\"'), (2, '0.084*\"sugar\" + 0.048*\"driving\" + 0.048*\"pressure\" + 0.048*\"increased\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxcJbKdpyzwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}